# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns

# Set random seed for reproducibility
np.random.seed(42)

# Step 1: Generate synthetic data
num_samples = 1000
server_load = np.random.uniform(50, 100, num_samples)  # Server Load (%)
external_temp = np.random.uniform(10, 40, num_samples)  # External Temperature (°C)
humidity = np.random.uniform(20, 80, num_samples)  # Humidity (%)

# Add variability to Cooling Output based on inputs
cooling_output = (
    15 * server_load +
    5 * external_temp +
    2 * humidity +
    np.random.normal(0, 50, num_samples)  # Add randomness for variability
)

# Simulate HVAC power consumption based on cooling output
hvac_power = cooling_output / 4 + np.random.normal(0, 20, num_samples)

# Create a DataFrame
data = pd.DataFrame({
    "Server Load (%)": server_load,
    "External Temperature (°C)": external_temp,
    "Humidity (%)": humidity,
    "Cooling Output (kWh)": cooling_output,
    "HVAC Power Consumption (kW)": hvac_power
})

# Step 2: Inspect the generated data
print(data.describe())  # View summary statistics

# Optional: Plot distribution of Cooling Output
sns.histplot(data['Cooling Output (kWh)'], bins=20, kde=True)
plt.title('Cooling Output (kWh) Distribution')
plt.show()

# Step 3: Prepare data for model training
X = data[['Server Load (%)', 'External Temperature (°C)', 'Humidity (%)']]
y = data['Cooling Output (kWh)']

# Step 4: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 5: Train Gradient Boosting model
gb_model = GradientBoostingRegressor(random_state=42)
gb_model.fit(X_train, y_train)

# Step 6: Predict and evaluate Gradient Boosting model
y_pred_gb = gb_model.predict(X_test)
mae_gb = mean_absolute_error(y_test, y_pred_gb)
print(f"Gradient Boosting MAE: {mae_gb:.2f}")

# Optionally, you could evaluate Random Forest and Linear Regression as well:
# Random Forest Model
# from sklearn.ensemble import RandomForestRegressor
# rf_model = RandomForestRegressor(random_state=42)
# rf_model.fit(X_train, y_train)
# y_pred_rf = rf_model.predict(X_test)
# mae_rf = mean_absolute_error(y_test, y_pred_rf)
# print(f"Random Forest MAE: {mae_rf:.2f}")

# Linear Regression Model
# from sklearn.linear_model import LinearRegression
# lr_model = LinearRegression()
# lr_model.fit(X_train, y_train)
# y_pred_lr = lr_model.predict(X_test)
# mae_lr = mean_absolute_error(y_test, y_pred_lr)
# print(f"Linear Regression MAE: {mae_lr:.2f}")
